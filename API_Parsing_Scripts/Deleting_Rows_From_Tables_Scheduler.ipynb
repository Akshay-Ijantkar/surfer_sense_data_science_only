{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Akshay Ijantkar\n",
    "### Team: Aqua Wizards\n",
    "### Project: Surfers Bible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://launchschool.com/books/sql/read/table_relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 1 * * * /usr/bin/python3 /home/ubuntu/pop_db_sch_ss/Daily_Scheduler_Swell_Pollution_Astro_News_API.py >> /home/ubuntu/pop_db_sch_ss/log_Daily_Scheduler_Swell_Pollution_Astro_News_API.txt 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "# import seaborn as sns; sns.set()\n",
    "# from scipy.stats import norm \n",
    "import matplotlib.pyplot as plt\n",
    "# For Linear regression\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# For split given dataset into train and test set.\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# To verify models using this metrics \n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# import statsmodels.formula.api as smf\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn import metrics\n",
    "# v\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 50,50\n",
    "import pandas_profiling\n",
    "pd.set_option('display.max_rows', 1500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "\n",
    "from pygeocoder import Geocoder\n",
    "\n",
    "import sys\n",
    "# from weather_au import api\n",
    "# from weather_au import summary\n",
    "# from weather import place, observations, uv_index\n",
    "import time\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "# from catboost import CatBoostClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.metrics import r2_score\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_validate\n",
    "\n",
    "# import catboost as ctb\n",
    "# from catboost import CatBoostRegressor, FeaturesData, Pool\n",
    "# from scipy.stats import uniform as sp_randFloat\n",
    "# from scipy.stats import randint as sp_randInt\n",
    "# from scipy.stats import uniform\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from  sklearn.metrics.pairwise import euclidean_distances\n",
    "# from sklearn.metrics.pairwise import manhattan_distances\n",
    "# from sklearn.metrics.pairwise import pairwise_distances\n",
    "import re\n",
    "# import pprint\n",
    "from datetime import date\n",
    "import datetime\n",
    "# import sqlite3\n",
    "# from sqlite3 import Error\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give Date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today_date =  2020-06-03\n",
      "given_date =  2020-05-29\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import datetime\n",
    "no_days_from_today = -5\n",
    "\n",
    "select_date = \"\"\n",
    "\n",
    "if select_date == \"\":    \n",
    "    today = date.today()\n",
    "    today_date = today.strftime(\"%Y-%m-%d\") \n",
    "    given_date =  str((datetime.datetime.strptime(today_date, \"%Y-%m-%d\") + datetime.timedelta(days = no_days_from_today)).date())\n",
    "    print(\"today_date = \", today_date)\n",
    "    print(\"given_date = \", given_date)\n",
    "else:\n",
    "    given_date = select_date\n",
    "    print(\"given_date = \", given_date)\n",
    "# print(\"today_date = \", today_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIO  TO EXCUTE SQL QUERY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql_func(sql_str, data_tuple):\n",
    "    import psycopg2 as ps\n",
    "\n",
    "    # define credentials \n",
    "    credentials = {'POSTGRES_ADDRESS' : 'test-surfers-bible-instance.cljoljhkgpfb.ap-southeast-2.rds.amazonaws.com', # change to your endpoint\n",
    "                   'POSTGRES_PORT' : 5432, # change to your port\n",
    "                   'POSTGRES_USERNAME' : '', # change to your username\n",
    "                   'POSTGRES_PASSWORD' : '', # change to your password\n",
    "                   'POSTGRES_DBNAME' : 'test_surfers_bible_db'} # change to your db name\n",
    "\n",
    "    # create connection and cursor    \n",
    "    conn = ps.connect(host=credentials['POSTGRES_ADDRESS'],\n",
    "                      database=credentials['POSTGRES_DBNAME'],\n",
    "                      user=credentials['POSTGRES_USERNAME'],\n",
    "                      password=credentials['POSTGRES_PASSWORD'],\n",
    "                      port=credentials['POSTGRES_PORT'])\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(sql_str, data_tuple)\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETE RECORDS FROM astronomy_table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_str = \"DELETE FROM public.astronomy_table WHERE date = %s ;\"\n",
    "execute_sql_func(sql_str = sql_str, data_tuple = (given_date,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETE RECORDS FROM extremes_height_table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_str = \"DELETE FROM public.extremes_height_table WHERE date = %s ;\"\n",
    "execute_sql_func(sql_str = sql_str, data_tuple = (given_date,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETE RECORDS FROM news_table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_str = \"DELETE FROM public.news_table WHERE date = %s ;\"\n",
    "execute_sql_func(sql_str = sql_str, data_tuple = (given_date,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETE RECORDS FROM sea_water_quality_table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_str = \"DELETE FROM public.sea_water_quality_table WHERE date = %s ;\"\n",
    "execute_sql_func(sql_str = sql_str, data_tuple = (given_date,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETE RECORDS FROM swell_table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_str = \"DELETE FROM public.swell_table WHERE date = %s ;\"\n",
    "execute_sql_func(sql_str = sql_str, data_tuple = (given_date,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETE RECORDS FROM tide_height_table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_str = \"DELETE FROM public.tide_height_table WHERE date = %s ;\"\n",
    "execute_sql_func(sql_str = sql_str, data_tuple = (given_date,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETE RECORDS FROM weather_table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_str = \"DELETE FROM public.weather_table WHERE date = %s ;\"\n",
    "execute_sql_func(sql_str = sql_str, data_tuple = (given_date,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sql_str = \"SELECT FROM public.weather_table WHERE date = %s ;\"\n",
    "# execute_sql_func(sql_str = sql_str, data_tuple = (given_date,))\n",
    "\n",
    "def get_table_as_df_func(select_query_str):\n",
    "    import psycopg2 as ps\n",
    "\n",
    "    # define credentials \n",
    "    credentials = {'POSTGRES_ADDRESS' : 'test-surfers-bible-instance.cljoljhkgpfb.ap-southeast-2.rds.amazonaws.com', # change to your endpoint\n",
    "                   'POSTGRES_PORT' : 5432, # change to your port\n",
    "                   'POSTGRES_USERNAME' : '', # change to your username\n",
    "                   'POSTGRES_PASSWORD' : '', # change to your password\n",
    "                   'POSTGRES_DBNAME' : 'test_surfers_bible_db'} # change to your db name\n",
    "\n",
    "    # create connection and cursor    \n",
    "    conn = ps.connect(host=credentials['POSTGRES_ADDRESS'],\n",
    "                      database=credentials['POSTGRES_DBNAME'],\n",
    "                      user=credentials['POSTGRES_USERNAME'],\n",
    "                      password=credentials['POSTGRES_PASSWORD'],\n",
    "                      port=credentials['POSTGRES_PORT'])\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # cur.execute(sql_str, data_tuple)\n",
    "    table_df = pd.read_sql(select_query_str , conn)\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return table_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df = get_table_as_df_func(\"SELECT * FROM sea_water_quality_table WHERE date = '2020-06-06';\")\n",
    "\n",
    "# table_df[table_df.beach_name == \"ZINETTIS BEACH NO. 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_df.beach_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather_id             0\n",
       "date                   0\n",
       "beach_id               0\n",
       "beach_name             0\n",
       "beach_latitude         0\n",
       "beach_longitude        0\n",
       "beach_state            0\n",
       "time                   0\n",
       "summary                0\n",
       "icon                   0\n",
       "precipintensity        0\n",
       "precipprobability      0\n",
       "temperature            0\n",
       "apparenttemperature    0\n",
       "dewpoint               0\n",
       "humidity               0\n",
       "pressure               0\n",
       "windspeed              0\n",
       "windgust               0\n",
       "windbearing            0\n",
       "cloudcover             0\n",
       "uvindex                0\n",
       "visibility             0\n",
       "ozone                  0\n",
       "nearest_station        0\n",
       "time_offset            0\n",
       "preciptype             0\n",
       "sources                0\n",
       "datetime               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_imputation_rf_func(df, \n",
    "                               feature_lst = [\n",
    "                                                'beach_latitude', \n",
    "                                                'beach_longitude', \n",
    "                                                'airtemperature', \n",
    "                                                'cloudcover', \n",
    "                                                'gust', \n",
    "                                                'humidity', \n",
    "                                                'precipitation', \n",
    "                                                'pressure', \n",
    "                                                'watertemperature', \n",
    "                                                'wavedirection', \n",
    "                                                'waveheight', \n",
    "                                                'waveperiod',\n",
    "                                           ],\n",
    "                              target_lst = [\n",
    "                                                'watertemperature', \n",
    "                                                'wavedirection', \n",
    "                                                'waveheight', \n",
    "                                                'waveperiod',                                  \n",
    "                                          ]):\n",
    "    miss_impu_df = df[feature_lst].copy()    \n",
    "    from missingpy import MissForest\n",
    "    imputer = MissForest()\n",
    "    X_imputed = imputer.fit_transform(miss_impu_df.values)\n",
    "    aft_miss_imp_df = pd.DataFrame(\n",
    "                      X_imputed, \n",
    "                      columns = feature_lst) \n",
    "    for col in target_lst:    \n",
    "        df[col] = aft_miss_imp_df[col].values\n",
    "        df[col] = df[col].apply(lambda x: round(x, 2))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n"
     ]
    }
   ],
   "source": [
    "swell_df = missing_imputation_rf_func(swell_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_str = \"DELETE FROM news_table WHERE title LIKE %s ;\"\n",
    "execute_sql_func(sql_str = sql_str, data_tuple = (\"\"\"\n",
    "%Daytona%\n",
    "\"\"\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
